{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHjnngbeSIea1rxwmSco4t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sr606/Machine_Learning_CaseStudies/blob/main/Jamboree_Education_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QzwHE7gJJ6d6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler , MinMaxScaler , PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "from scipy import stats\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats.api as sms\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jm_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Scaler/Jamboree_Admission.csv')\n",
        "df = jm_data.copy()\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "SdcE2RzGKIHg",
        "outputId": "3c1ff9fc-98dd-4444-8b72-db10e067ba9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Scaler/Jamboree_Admission.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d2f2a77ee3bc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjm_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Scaler/Jamboree_Admission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjm_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Scaler/Jamboree_Admission.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'Chance of Admit ': 'Chance_of_Admit'})"
      ],
      "metadata": {
        "id": "4Zrh6u7hKJCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "5mXFQFalKJFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "r1k9PhZHKJJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.cov()"
      ],
      "metadata": {
        "id": "gvKr7PI7KJMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "GvPs2rkYKJO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns='Serial No.')\n",
        "df.sample()"
      ],
      "metadata": {
        "id": "HGQet1FvKJRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "GJvy6jKHKptm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.duplicated()]"
      ],
      "metadata": {
        "id": "T5Ya6nhTKpw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqg-j6QrK_Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().any()"
      ],
      "metadata": {
        "id": "iwtmtPXWKp0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "a_XJ5D9aK_mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,8))\n",
        "plt.style.use('dark_background')\n",
        "sns.heatmap(df.isnull(),cmap='Greens')\n",
        "plt.title('Visual Check of Nulls',fontsize=20,color='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0mh4gPO5K_r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in df.columns:\n",
        "    print()\n",
        "    print(f'Total Unique Values in {_} column are :- {df[_].nunique()}')\n",
        "    print(f'Value counts in {_} column are :-\\n {df[_].value_counts(normalize=True)}')\n",
        "    print()\n",
        "    print('-'*120)"
      ],
      "metadata": {
        "id": "Wl9WuleTK_vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in df.columns:\n",
        "    print()\n",
        "    print(f'Range of {_} column is from {df[_].min()} to {df[_].max()}')\n",
        "    print()\n",
        "    print('-'*120)"
      ],
      "metadata": {
        "id": "OwgtEVIfK_yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "z_UJd2cEf6JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp = 'Greens'"
      ],
      "metadata": {
        "id": "-4q8lUHCf6MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in df.columns:\n",
        "    plt.style.use('default')\n",
        "    plt.style.use('fast')\n",
        "    plt.figure(figsize = (18,4))\n",
        "    plt.subplot(122)\n",
        "    sns.boxplot(df[_],palette=cp)\n",
        "    plt.subplot(121)\n",
        "    sns.histplot(df[_],kde=True,color='g')\n",
        "    plt.suptitle(f'Plot of {_}',fontsize=14,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "    sns.despine()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Jc4adFvMf6PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "    plt.figure(figsize=(25,5))\n",
        "    plt.style.use('default')\n",
        "    plt.style.use('fast')\n",
        "    b = sns.countplot(x=df[col],palette=cp)\n",
        "    plt.title(f'Distribution of {col}',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "    b.bar_label(b.containers[0], label_type='edge',fmt='%d')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count of Students')\n",
        "    plt.tight_layout()\n",
        "    sns.despine()\n",
        "    plt.show();"
      ],
      "metadata": {
        "id": "06Xakbmxf6SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "4GB6kil-f6VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data=df, y_vars='Chance_of_Admit')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cygiX3fdf6YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df.corr(),y_vars='Chance_of_Admit',kind= 'reg')"
      ],
      "metadata": {
        "id": "8qNiCq-Bf6aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "MvTBCboSf6dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns[:-1]:\n",
        "    print(col)\n",
        "    sns.jointplot(data=df,x=df[col],y=df[\"Chance_of_Admit\"],kind=\"reg\",color='g')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Yf42_UbNgGXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns[:-1]:\n",
        "    print(f\"Plotting regression plot for: {col}\")\n",
        "    sns.regplot(data=df, x=col, y=\"Chance_of_Admit\", color='g')\n",
        "    plt.title(f'Regression Plot: {col} vs Chance_of_Admit')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mcT4KYQZgGaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.heatmap(df.corr(), annot = True, cmap = 'Greens', linewidths = 0.1)#mask=np.triu(df.corr()))\n",
        "plt.title(f'Correlations',fontsize=14,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7kOpW90pgGdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Initialize the LocalOutlierFactor model\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
        "\n",
        "# Fit the model and predict outliers\n",
        "outliers = lof.fit_predict(df)\n",
        "\n",
        "# Add the outlier column to the dataframe\n",
        "df['Outlier'] = outliers\n",
        "\n",
        "# Display the outliers\n",
        "outliers_df = df[df['Outlier'] == -1]\n",
        "outliers_df"
      ],
      "metadata": {
        "id": "QekHedYKgGgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate the model\n",
        "def model_evaluation(y_true, y_pred, model):\n",
        "    print(f\"Model: {model}\")\n",
        "    print(f\"R2 Score: {r2_score(y_true, y_pred)}\")\n",
        "    print(f\"Mean Absolute Error: {mean_absolute_error(y_true, y_pred)}\")\n",
        "    print(f\"Mean Squared Error: {mean_squared_error(y_true, y_pred)}\")\n",
        "    print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_true, y_pred))}\")\n",
        "    print()\n",
        "\n",
        "# Remove outliers from the dataset\n",
        "df_no_outliers = df[df['Outlier'] != -1]\n",
        "\n",
        "# Statistical summary comparison\n",
        "print(\"Statistical Summary with Outliers:\")\n",
        "display(df.describe())\n",
        "\n",
        "print(\"\\nStatistical Summary without Outliers:\")\n",
        "display(df_no_outliers.describe())\n",
        "\n",
        "# Split the data into features and target variable\n",
        "x_with_outliers = df.drop(columns=['Chance_of_Admit', 'Outlier'])\n",
        "y_with_outliers = df['Chance_of_Admit']\n",
        "\n",
        "x_without_outliers = df_no_outliers.drop(columns=['Chance_of_Admit', 'Outlier'])\n",
        "y_without_outliers = df_no_outliers['Chance_of_Admit']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "x_train_with, x_test_with, y_train_with, y_test_with = train_test_split(\n",
        "    x_with_outliers, y_with_outliers, test_size=0.2, random_state=42\n",
        ")\n",
        "x_train_without, x_test_without, y_train_without, y_test_without = train_test_split(\n",
        "    x_without_outliers, y_without_outliers, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Standardize the data\n",
        "scaler_with_outliers = StandardScaler()\n",
        "x_train_with = scaler_with_outliers.fit_transform(x_train_with)  # Fit and transform training data\n",
        "x_test_with = scaler_with_outliers.transform(x_test_with)        # Only transform test data\n",
        "\n",
        "scaler_without_outliers = StandardScaler()\n",
        "x_train_without = scaler_without_outliers.fit_transform(x_train_without)  # Fit and transform training data\n",
        "x_test_without = scaler_without_outliers.transform(x_test_without)        # Only transform test data\n",
        "\n",
        "# Train a Linear Regression model on the data with outliers\n",
        "lr_with_outliers = LinearRegression()\n",
        "lr_with_outliers.fit(x_train_with, y_train_with)\n",
        "\n",
        "# Train a Linear Regression model on the data without outliers\n",
        "lr_without_outliers = LinearRegression()\n",
        "lr_without_outliers.fit(x_train_without, y_train_without)\n",
        "\n",
        "# Predict and evaluate the model performance with outliers\n",
        "y_pred_train_with = lr_with_outliers.predict(x_train_with)\n",
        "y_pred_test_with = lr_with_outliers.predict(x_test_with)\n",
        "print(\"\\nModel Performance with Outliers:\")\n",
        "model_evaluation(y_train_with, y_pred_train_with, \"Linear Regression (with outliers)\")\n",
        "model_evaluation(y_test_with, y_pred_test_with, \"Linear Regression (with outliers)\")\n",
        "print()\n",
        "\n",
        "# Predict and evaluate the model performance without outliers\n",
        "y_pred_train_without = lr_without_outliers.predict(x_train_without)\n",
        "y_pred_test_without = lr_without_outliers.predict(x_test_without)\n",
        "print(\"\\nModel Performance without Outliers:\")\n",
        "model_evaluation(y_train_without, y_pred_train_without, \"Linear Regression (without outliers)\")\n",
        "model_evaluation(y_test_without, y_pred_test_without, \"Linear Regression (without outliers)\")\n",
        "print()"
      ],
      "metadata": {
        "id": "o44FOXWigGip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_with_outliers , y_with_outliers"
      ],
      "metadata": {
        "id": "tzXHmaEkgG3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_with , y_train_with"
      ],
      "metadata": {
        "id": "iuFkd-d6gG59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_with , y_test_with"
      ],
      "metadata": {
        "id": "GwuyqBDpgG88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note : Train is fit_transformed & test is just transformed\n",
        "x_train_scaled = x_train_with\n",
        "y_train = y_train_with\n",
        "x_test_scaled = x_test_with\n",
        "y_test = y_test_with"
      ],
      "metadata": {
        "id": "YgYhhEJ6gG_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = scaled_df.iloc[:,:-1]\n",
        "# y = scaled_df.iloc[:,-1]\n",
        "print(x_train_scaled.shape , y_train.shape)\n",
        "print(x_test_scaled.shape , y_test.shape)"
      ],
      "metadata": {
        "id": "Yd40BShBgX4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of x_train: {x_train_scaled.shape}')\n",
        "print(f'Shape of x_test: {x_test_scaled.shape}')\n",
        "print(f'Shape of y_train: {y_train.shape}')\n",
        "print(f'Shape of y_test: {y_test.shape}')"
      ],
      "metadata": {
        "id": "PqN2UW_xgX7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegression()\n",
        "lr_model.fit(x_train_scaled,y_train)"
      ],
      "metadata": {
        "id": "GWWSvT97gX-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting values for the training and test data\n",
        "y_pred_train = lr_model.predict(x_train_scaled)\n",
        "y_pred_test = lr_model.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "W3R5719sgYBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_train,y_pred_train)"
      ],
      "metadata": {
        "id": "-vIIjBzDgYDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.score(x_train_scaled,y_train)"
      ],
      "metadata": {
        "id": "yytOstBHgYGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,y_pred_test)"
      ],
      "metadata": {
        "id": "8sU5Q79MgYJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.score(x_test_scaled,y_test)"
      ],
      "metadata": {
        "id": "HCMMX6pNgYMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "oEkj68kogYOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model_weights = pd.DataFrame([lr_model.coef_], columns=df.columns[:-2])\n",
        "lr_model_weights['Intercept'] = lr_model.intercept_\n",
        "lr_model_weights"
      ],
      "metadata": {
        "id": "qQXUsoHVg3ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjusted_r2_score(y_true, y_pred, model):\n",
        "    # Get the number of data points (n) and the number of features (p)\n",
        "    n = len(y_true)\n",
        "    p = x_train_scaled.shape[1]  # Use the number of features from training data (x_train_with)\n",
        "\n",
        "    # Calculate R² score\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    # Calculate Adjusted R²\n",
        "    adj_r2 = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)\n",
        "\n",
        "    return adj_r2\n",
        "\n",
        "def model_evaluation(y_true, y_pred, model, x_train):\n",
        "    print(f\"Model: {model}\")\n",
        "    print(f\"R2 Score: {r2_score(y_true, y_pred)}\")\n",
        "    print(f\"Adjusted R2 Score: {adjusted_r2_score(y_true, y_pred, model)}\")\n",
        "    print(f\"Mean Absolute Error: {mean_absolute_error(y_true, y_pred)}\")\n",
        "    print(f\"Mean Squared Error: {mean_squared_error(y_true, y_pred)}\")\n",
        "    print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_true, y_pred))}\")\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "id": "wBRT2n6tg3cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model Performance of training data:\")\n",
        "model_evaluation(y_train, y_pred_train, lr_model, x_train_scaled)"
      ],
      "metadata": {
        "id": "4IlGVbTng3fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model Performance of test data:\")\n",
        "model_evaluation(y_test, y_pred_test, lr_model, x_train_scaled)"
      ],
      "metadata": {
        "id": "HaC50kNpg3h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_x_train = sm.add_constant(x_with_outliers)\n",
        "model = sm.OLS(y_with_outliers, new_x_train)\n",
        "results = model.fit()\n",
        "\n",
        "# statstical summary of the model\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "So0Hcik6g3ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_x_train = sm.add_constant(x_train_scaled)\n",
        "model = sm.OLS(y_train, new_x_train)\n",
        "results = model.fit()\n",
        "\n",
        "# statstical summary of the model\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "6SLyVrTxg3nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vif = pd.DataFrame()\n",
        "vif['Variable'] = x_with_outliers.columns\n",
        "vif['VIF'] = [variance_inflation_factor(x_train_scaled, i) for i in range(x_train_scaled.shape[1])]\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif"
      ],
      "metadata": {
        "id": "N7Pni3osg3pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the features and target variable for the data with outliers\n",
        "x_with_outliers = df.drop(columns=['Chance_of_Admit', 'Outlier'])\n",
        "y_with_outliers = df['Chance_of_Admit']\n",
        "\n",
        "# Apply MinMax Scaling to the data with outliers\n",
        "scaler_with_outliers = MinMaxScaler()\n",
        "x_train_with_minmax = scaler_with_outliers.fit_transform(x_with_outliers)  # Fit and transform training data\n",
        "x_test_with_minmax = scaler_with_outliers.transform(x_with_outliers)  # Only transform test data\n",
        "\n",
        "# Convert the scaled data into a DataFrame for easier manipulation\n",
        "x_train_with_minmax_df = pd.DataFrame(x_train_with_minmax, columns=x_with_outliers.columns)\n",
        "\n",
        "# Calculate the VIF for each variable in the training set (with outliers)\n",
        "vif = pd.DataFrame()\n",
        "vif['Variable'] = x_train_with_minmax_df.columns\n",
        "vif['VIF'] = [variance_inflation_factor(x_train_with_minmax_df.values, i) for i in range(x_train_with_minmax_df.shape[1])]\n",
        "vif = vif.sort_values(by=\"VIF\", ascending=False)\n",
        "\n",
        "# Display the VIF values for the data with outliers\n",
        "print(vif)\n"
      ],
      "metadata": {
        "id": "XdNkAktwhGKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out the outliers from the dataframe\n",
        "df_no_outliers = df[df['Outlier'] != -1]\n",
        "\n",
        "# Define features and target variable for the data with and without outliers\n",
        "x_without_outliers = df_no_outliers.drop(columns=['Chance_of_Admit', 'Outlier'])\n",
        "y_without_outliers = df_no_outliers['Chance_of_Admit']\n",
        "\n",
        "x_with_outliers = df.drop(columns=['Chance_of_Admit', 'Outlier'])\n",
        "y_with_outliers = df['Chance_of_Admit']\n",
        "\n",
        "# Apply MinMax Scaling to the data with outliers\n",
        "scaler_with_outliers = MinMaxScaler()\n",
        "x_train_with_minmax = scaler_with_outliers.fit_transform(x_with_outliers)  # Fit and transform training data\n",
        "x_test_with_minmax = scaler_with_outliers.transform(x_with_outliers)  # Only transform test data\n",
        "\n",
        "# Convert the scaled data into a DataFrame for easier manipulation\n",
        "x_train_with_minmax_df = pd.DataFrame(x_train_with_minmax, columns=x_with_outliers.columns)\n",
        "\n",
        "# Calculate the VIF for each variable in the training set (with outliers)\n",
        "vif_with_outliers = pd.DataFrame()\n",
        "vif_with_outliers['Variable'] = x_train_with_minmax_df.columns\n",
        "vif_with_outliers['VIF'] = [variance_inflation_factor(x_train_with_minmax_df.values, i) for i in range(x_train_with_minmax_df.shape[1])]\n",
        "vif_with_outliers = vif_with_outliers.sort_values(by=\"VIF\", ascending=False)\n",
        "\n",
        "# Display the VIF values for the data with outliers\n",
        "print(\"VIF for data with outliers:\")\n",
        "print(vif_with_outliers)\n",
        "\n",
        "# Apply MinMax Scaling to the data without outliers\n",
        "scaler_without_outliers = MinMaxScaler()\n",
        "x_train_without_minmax = scaler_without_outliers.fit_transform(x_without_outliers)  # Fit and transform training data\n",
        "x_test_without_minmax = scaler_without_outliers.transform(x_without_outliers)  # Only transform test data\n",
        "\n",
        "# Convert the scaled data into a DataFrame for easier manipulation\n",
        "x_train_without_minmax_df = pd.DataFrame(x_train_without_minmax, columns=x_without_outliers.columns)\n",
        "\n",
        "# Calculate the VIF for each variable in the training set (without outliers)\n",
        "vif_without_outliers = pd.DataFrame()\n",
        "vif_without_outliers['Variable'] = x_train_without_minmax_df.columns\n",
        "vif_without_outliers['VIF'] = [variance_inflation_factor(x_train_without_minmax_df.values, i) for i in range(x_train_without_minmax_df.shape[1])]\n",
        "vif_without_outliers = vif_without_outliers.sort_values(by=\"VIF\", ascending=False)\n",
        "\n",
        "# Display the VIF values for the data without outliers\n",
        "print(\"VIF for data without outliers:\")\n",
        "print(vif_without_outliers)\n"
      ],
      "metadata": {
        "id": "2JmL8e-6hGNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_test.values - y_pred_test"
      ],
      "metadata": {
        "id": "DotcbkjhhGQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals_train = y_train.values - y_pred_train\n",
        "residuals_train.mean()"
      ],
      "metadata": {
        "id": "uASTmr4ahGTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals.mean()"
      ],
      "metadata": {
        "id": "_2BJkF44hGVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.histplot(residuals, kde= True,color='g')\n",
        "plt.title('Residuals Hist',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='mediumseagreen',color='w')\n",
        "sns.despine(left=True)\n",
        "plt.ylabel(\"\")\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EQmdAzXqhGYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.histplot(residuals_train, kde= True,color='g')\n",
        "plt.title('Residuals Hist',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='mediumseagreen',color='w')\n",
        "sns.despine(left=True)\n",
        "plt.ylabel(\"\")\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jfkEmS8QhGaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(121)\n",
        "plt.title('Residuals_train data',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "sns.regplot(x=y_pred_train, y=residuals_train, lowess=True, color='g',line_kws={'color': 'red'})\n",
        "plt.axhline(y=0, color='k', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.subplot(122)\n",
        "plt.title('Residuals_test data',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "sns.regplot(x=y_pred_test, y=residuals, lowess=True,color='g' ,line_kws={'color': 'red'})\n",
        "plt.axhline(y=0, color='k', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5VPRDO7uhGdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplot of residuals with each independent variable to check for Homoscedasticity\n",
        "plt.figure(figsize=(15,8))\n",
        "i=1\n",
        "for col in x_test.columns[:-1]:\n",
        "    plt.subplot(2,3,i)\n",
        "    sns.scatterplot(x=x_test[col].values.reshape((-1,)), y=residuals.reshape((-1,)),color='g')\n",
        "    plt.title(f'Residual Plot with {col}',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Residual')\n",
        "    i+=1\n",
        "\n",
        "plt.tight_layout()\n",
        "sns.despine()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "EdGdIMywhQoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ols_model = results\n",
        "predicted = ols_model.predict()\n",
        "residuals = ols_model.resid"
      ],
      "metadata": {
        "id": "PcWmcaiDhTP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gq_test_results = sms.het_goldfeldquandt(residuals, ols_model.model.exog)\n",
        "gq_test_results"
      ],
      "metadata": {
        "id": "N2lj9GGnhQrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Breusch-Pagan Test for Homoscedasticity\n",
        "residuals = ols_model.resid\n",
        "bp_test_results = sms.het_breuschpagan(residuals, ols_model.model.exog)\n",
        "\n",
        "# Creating DataFrame for Breusch-Pagan Test results\n",
        "bp_test = pd.DataFrame(bp_test_results,\n",
        "                       columns=['value'],\n",
        "                       index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n",
        "\n",
        "# 2. Goldfeld-Quandt Test for Homoscedasticity\n",
        "gq_test_results = sms.het_goldfeldquandt(residuals, ols_model.model.exog)\n",
        "gq_test_df = pd.DataFrame([gq_test_results], columns=['Test Statistic', 'p-value','Trend'])\n",
        "\n",
        "# Print Breusch-Pagan Test results\n",
        "print(\"Breusch-Pagan Test Results:\")\n",
        "print(bp_test)\n",
        "\n",
        "# Print Goldfeld-Quandt Test results\n",
        "print(\"\\nGoldfeld-Quandt Test Results:\")\n",
        "print(gq_test_df)\n",
        "\n",
        "# Interpretation for Breusch-Pagan Test\n",
        "bp_p_value = bp_test.loc['p-value', 'value']\n",
        "if bp_p_value < 0.05:\n",
        "    print(\"\\nBreusch-Pagan Test Interpretation: Heteroscedasticity is present (p-value < 0.05).\")\n",
        "else:\n",
        "    print(\"\\nBreusch-Pagan Test Interpretation: Heteroscedasticity is not present (p-value >= 0.05).\")\n",
        "\n",
        "# Interpretation for Goldfeld-Quandt Test\n",
        "gq_p_value = gq_test_df.loc[0, 'p-value']\n",
        "if gq_p_value < 0.05:\n",
        "    print(\"Goldfeld-Quandt Test Interpretation: Heteroscedasticity is present (p-value < 0.05).\")\n",
        "else:\n",
        "    print(\"Goldfeld-Quandt Test Interpretation: Heteroscedasticity is not present (p-value >= 0.05).\")\n",
        "\n"
      ],
      "metadata": {
        "id": "V69k4CKShQv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. White Test for Homoscedasticity\n",
        "white_test_results = sms.het_white(ols_model.resid, ols_model.model.exog)\n",
        "\n",
        "# 2. Creating DataFrame for White Test results\n",
        "white_test_df = pd.DataFrame(white_test_results,\n",
        "                             columns=['value'],\n",
        "                             index=['Test Statistic', 'p-value', 'f-value', 'f p-value'])\n",
        "\n",
        "# Print White Test results\n",
        "print(\"\\nWhite Test Results:\")\n",
        "print(white_test_df)\n",
        "\n",
        "# Interpretation for White Test\n",
        "white_p_value = white_test_df.loc['p-value', 'value']\n",
        "if white_p_value < 0.05:\n",
        "    print(\"\\nWhite Test Interpretation: Heteroscedasticity is present (p-value < 0.05).\")\n",
        "else:\n",
        "    print(\"\\nWhite Test Interpretation: Heteroscedasticity is not present (p-value >= 0.05).\")"
      ],
      "metadata": {
        "id": "KxNrxKPdhXrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Breusch-Pagan Test for Homoscedasticity\n",
        "residuals = lr_model.resid\n",
        "bp_test_results = sms.het_breuschpagan(residuals, lr_model.model.exog)\n",
        "\n",
        "# Creating DataFrame for Breusch-Pagan Test results\n",
        "bp_test = pd.DataFrame(bp_test_results,\n",
        "                       columns=['value'],\n",
        "                       index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n",
        "\n",
        "# 2. Goldfeld-Quandt Test for Homoscedasticity\n",
        "gq_test_results = sms.het_goldfeldquandt(residuals, lr_model.model.exog)\n",
        "gq_test_df = pd.DataFrame([gq_test_results], columns=['Test Statistic', 'p-value','Trend'])\n",
        "\n",
        "# Print Breusch-Pagan Test results\n",
        "print(\"Breusch-Pagan Test Results:\")\n",
        "print(bp_test)\n",
        "\n",
        "# Print Goldfeld-Quandt Test results\n",
        "print(\"\\nGoldfeld-Quandt Test Results:\")\n",
        "print(gq_test_df)\n",
        "\n",
        "# Interpretation for Breusch-Pagan Test\n",
        "bp_p_value = bp_test.loc['p-value', 'value']\n",
        "if bp_p_value < 0.05:\n",
        "    print(\"\\nBreusch-Pagan Test Interpretation: Heteroscedasticity is present (p-value < 0.05).\")\n",
        "else:\n",
        "    print(\"\\nBreusch-Pagan Test Interpretation: Heteroscedasticity is not present (p-value >= 0.05).\")\n",
        "\n",
        "# Interpretation for Goldfeld-Quandt Test\n",
        "gq_p_value = gq_test_df.loc[0, 'p-value']\n",
        "if gq_p_value < 0.05:\n",
        "    print(\"Goldfeld-Quandt Test Interpretation: Heteroscedasticity is present (p-value < 0.05).\")\n",
        "else:\n",
        "    print(\"Goldfeld-Quandt Test Interpretation: Heteroscedasticity is not present (p-value >= 0.05).\")\n"
      ],
      "metadata": {
        "id": "JrlQFdZ7hQyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.histplot(residuals, kde= True,color='g')\n",
        "plt.title('Residuals Hist',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='mediumseagreen',color='w')\n",
        "sns.despine(left=True)\n",
        "plt.ylabel(\"\")\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HVdNJxBnhQ1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QQ-Plot of residuals\n",
        "plt.figure(figsize=(15,5))\n",
        "sm.qqplot(residuals,line='45')\n",
        "plt.title('QQ Plot of Residuals',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "plt.ylabel('Residual Quantiles')\n",
        "sns.despine()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "BUVuWODkhQ4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jb_stat, jb_p_value = stats.jarque_bera(residuals)\n",
        "\n",
        "\n",
        "print(\"Jarque-Bera Test Statistic:\", jb_stat)\n",
        "print(\"p-value:\", jb_p_value)\n",
        "\n",
        "if jb_p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: Residuals are not normally distributed.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: Residuals are normally distributed.\")"
      ],
      "metadata": {
        "id": "qaQ_QECchd03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# --- LassoCV for Optimal Alpha ---\n",
        "lasso_cv = LassoCV(\n",
        "    alphas=np.logspace(-4, 4, 100),  # Range of alpha values\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    max_iter=10000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit LassoCV on training data\n",
        "lasso_cv.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Get the optimal alpha\n",
        "optimal_alpha_lassocv = lasso_cv.alpha_\n",
        "print(f\"Optimal alpha for Lasso (LassoCV): {optimal_alpha_lassocv}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred_lassocv = lasso_cv.predict(x_test_scaled)\n",
        "\n",
        "# Metrics\n",
        "mse = mean_squared_error(y_test, y_pred_lassocv)\n",
        "r2 = r2_score(y_test, y_pred_lassocv)\n",
        "print(f\"Test MSE: {mse}\")\n",
        "print(f\"Test R2 Score: {r2}\")\n"
      ],
      "metadata": {
        "id": "XlUBPCA7hfPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lasso = Lasso(alpha=0.0006428073117284319)\n",
        "model_lasso.fit(x_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "96KssYBkhgnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ridge = Ridge()\n",
        "model_ridge.fit(x_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "_GCwn_Xohh5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_ridge = model_ridge.predict(x_train_scaled)\n",
        "y_pred_test_ridge = model_ridge.predict(x_test_scaled)\n",
        "\n",
        "y_pred_train_lasso = model_lasso.predict(x_train_scaled)\n",
        "y_pred_test_lasso = model_lasso.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "cPUFS46ghjLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_model_weights = pd.DataFrame(model_lasso.coef_.reshape(1,-1),columns=df.columns[:-2])\n",
        "lasso_model_weights[\"Intercept\"] = model_lasso.intercept_\n",
        "lasso_model_weights"
      ],
      "metadata": {
        "id": "PZyhcbgyhj1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_model_weights = pd.DataFrame(model_ridge.coef_.reshape(1,-1),columns=df.columns[:-2])\n",
        "ridge_model_weights[\"Intercept\"] = model_ridge.intercept_\n",
        "ridge_model_weights"
      ],
      "metadata": {
        "id": "Lmq8HP_0hj42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Linear Regression Training Accuracy\\n')\n",
        "model_evaluation(y_train.values, y_pred_train, lr_model,x_train_scaled)\n",
        "print('*'*25)\n",
        "print('\\nLinear Regression Test Accuracy\\n')\n",
        "model_evaluation(y_test.values, y_pred_test, lr_model,x_train_scaled)\n",
        "print('---'*25)\n",
        "print('\\nRidge Regression Training Accuracy\\n')\n",
        "model_evaluation(y_train.values, y_pred_train_ridge, model_ridge,x_train_scaled)\n",
        "print('*'*25)\n",
        "print('\\n\\nRidge Regression Test Accuracy\\n')\n",
        "model_evaluation(y_test.values, y_pred_test_ridge, model_ridge,x_train_scaled)\n",
        "print('---'*25)\n",
        "print('\\n\\nLasso Regression Training Accuracy\\n')\n",
        "model_evaluation(y_train.values, y_pred_train_lasso, model_lasso,x_train_scaled)\n",
        "print('*'*25)\n",
        "print('\\n\\nLasso Regression Test Accuracy\\n')\n",
        "model_evaluation(y_test.values, y_pred_test_lasso, model_lasso,x_train_scaled)\n",
        "print('---'*25)"
      ],
      "metadata": {
        "id": "PgECYfwhhj7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_values = y_train.values.reshape((-1,))\n",
        "predicted_values = [y_pred_train.reshape((-1,)), y_pred_train_ridge.reshape((-1,)), y_pred_train_lasso.reshape((-1,))]\n",
        "model = ['Linear Regression', 'Ridge Regression', 'Lasso Regression']\n",
        "plt.figure(figsize=(15,5))\n",
        "i=1\n",
        "for preds in predicted_values:\n",
        "    plt.subplot(1,3,i)\n",
        "    sns.scatterplot(x=actual_values, y=preds,color='g')\n",
        "    plt.plot([np.min(actual_values), np.max(actual_values)], [np.min(actual_values), np.max(actual_values)], 'r-')\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title(model[i-1],fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "    i+=1\n",
        "plt.tight_layout()\n",
        "sns.despine()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "zncUw38Qhj-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Define alpha range\n",
        "alpha_range = np.logspace(-4, 4, 50)  # Small to large values of alpha\n",
        "\n",
        "# --- LASSO with GridSearchCV ---\n",
        "lasso = Lasso(max_iter=10000)\n",
        "grid_lasso = GridSearchCV(\n",
        "    lasso,\n",
        "    param_grid={\"alpha\": alpha_range},\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5\n",
        ")\n",
        "grid_lasso.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Optimal alpha for Lasso\n",
        "optimal_alpha_lasso = grid_lasso.best_params_['alpha']\n",
        "print(f\"Optimal alpha for Lasso (GridSearchCV): {optimal_alpha_lasso}\")\n",
        "\n",
        "# --- RIDGE with GridSearchCV ---\n",
        "ridge = Ridge()\n",
        "grid_ridge = GridSearchCV(\n",
        "    ridge,\n",
        "    param_grid={\"alpha\": alpha_range},\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5\n",
        ")\n",
        "grid_ridge.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Optimal alpha for Ridge\n",
        "optimal_alpha_ridge = grid_ridge.best_params_['alpha']\n",
        "print(f\"Optimal alpha for Ridge (GridSearchCV): {optimal_alpha_ridge}\")\n",
        "\n",
        "# --- RandomizedSearchCV ---\n",
        "random_lasso = RandomizedSearchCV(\n",
        "    lasso,\n",
        "    param_distributions={\"alpha\": alpha_range},\n",
        "    n_iter=20,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "random_lasso.fit(x_train_scaled, y_train)\n",
        "optimal_alpha_lasso_random = random_lasso.best_params_['alpha']\n",
        "print(f\"Optimal alpha for Lasso (RandomizedSearchCV): {optimal_alpha_lasso_random}\")\n",
        "\n",
        "random_ridge = RandomizedSearchCV(\n",
        "    ridge,\n",
        "    param_distributions={\"alpha\": alpha_range},\n",
        "    n_iter=20,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "random_ridge.fit(x_train_scaled, y_train)\n",
        "optimal_alpha_ridge_random = random_ridge.best_params_['alpha']\n",
        "print(f\"Optimal alpha for Ridge (RandomizedSearchCV): {optimal_alpha_ridge_random}\")\n",
        "\n",
        "# --- AIC / BIC Method ---\n",
        "def calculate_aic_bic(model, x, y):\n",
        "    # Fit the model\n",
        "    model.fit(x, y)\n",
        "    predictions = model.predict(x)\n",
        "    residual_sum_of_squares = mean_squared_error(y, predictions) * len(y)\n",
        "    n, p = x.shape  # Number of samples, number of predictors\n",
        "    aic = n * np.log(residual_sum_of_squares / n) + 2 * p\n",
        "    bic = n * np.log(residual_sum_of_squares / n) + p * np.log(n)\n",
        "    return aic, bic\n",
        "\n",
        "# Calculate AIC / BIC for Lasso\n",
        "aic_lasso, bic_lasso = calculate_aic_bic(Lasso(alpha=optimal_alpha_lasso), x_test_scaled, y_test)\n",
        "print(f\"AIC for Lasso: {aic_lasso}, BIC for Lasso: {bic_lasso}\")\n",
        "\n",
        "# Calculate AIC / BIC for Ridge\n",
        "aic_ridge, bic_ridge = calculate_aic_bic(Ridge(alpha=optimal_alpha_ridge), x_test_scaled, y_test)\n",
        "print(f\"AIC for Ridge: {aic_ridge}, BIC for Ridge: {bic_ridge}\")\n",
        "\n",
        "# --- Final Testing with Optimal Alphas ---\n",
        "lasso_final = Lasso(alpha=optimal_alpha_lasso)\n",
        "lasso_final.fit(x_train_scaled, y_train)\n",
        "lasso_test_score = lasso_final.score(x_test_scaled, y_test)\n",
        "print(f\"Lasso Test Score with optimal alpha: {lasso_test_score}\")\n",
        "\n",
        "ridge_final = Ridge(alpha=optimal_alpha_ridge)\n",
        "ridge_final.fit(x_train_scaled, y_train)\n",
        "ridge_test_score = ridge_final.score(x_test_scaled, y_test)\n",
        "print(f\"Ridge Test Score with optimal alpha: {ridge_test_score}\")\n"
      ],
      "metadata": {
        "id": "dxeEm2xchkBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# --- ElasticNetCV for Optimal Alpha and L1 Ratio ---\n",
        "elasticnet_cv = ElasticNetCV(\n",
        "    alphas=np.logspace(-4, 4, 100),  # Range of alpha values\n",
        "    l1_ratio=np.linspace(0.1, 1.0, 10),  # Range of l1_ratio values\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    max_iter=10000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit ElasticNetCV on training data\n",
        "elasticnet_cv.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Get the optimal alpha and l1_ratio\n",
        "optimal_alpha_elasticnet = elasticnet_cv.alpha_\n",
        "optimal_l1_ratio_elasticnet = elasticnet_cv.l1_ratio_\n",
        "print(f\"Optimal alpha for ElasticNet: {optimal_alpha_elasticnet}\")\n",
        "print(f\"Optimal l1_ratio for ElasticNet: {optimal_l1_ratio_elasticnet}\")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred_elasticnet = elasticnet_cv.predict(x_test_scaled)\n",
        "\n",
        "# Metrics\n",
        "mse = mean_squared_error(y_test, y_pred_elasticnet)\n",
        "r2 = r2_score(y_test, y_pred_elasticnet)\n",
        "print(f\"Test MSE: {mse}\")\n",
        "print(f\"Test R2 Score: {r2}\")\n"
      ],
      "metadata": {
        "id": "L80yr7_khkDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ElasticNet_model = ElasticNet(alpha=0.108)\n",
        "# ElasticNet_model.fit(x_train , y_train)\n",
        "ElasticNet_model = ElasticNet(alpha=0.108)\n",
        "ElasticNet_model.fit(x_train_scaled , y_train)"
      ],
      "metadata": {
        "id": "Nk2Piiwvhup9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_en = ElasticNet_model.predict(x_train_scaled)\n",
        "y_pred_test_en = ElasticNet_model.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "2tA560LkhutY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_R2 = ElasticNet_model.score(x_train_scaled,y_train)\n",
        "test_R2 = ElasticNet_model.score(x_test_scaled,y_test)\n",
        "train_R2 , test_R2"
      ],
      "metadata": {
        "id": "PWCJg-LAhxId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_model_weights = pd.DataFrame(ElasticNet_model.coef_.reshape(1,-1),columns=df.columns[:-2])\n",
        "en_model_weights[\"Intercept\"] = ElasticNet_model.intercept_\n",
        "en_model_weights"
      ],
      "metadata": {
        "id": "D50FJXfQhytu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('ElasticNet Regression Training Accuracy\\n')\n",
        "model_evaluation(y_train.values, y_pred_train_en, ElasticNet_model,x_train_scaled)\n",
        "print('*'*25)\n",
        "print('\\nElasticNet Regression Test Accuracy\\n')\n",
        "model_evaluation(y_test.values, y_pred_test_en, ElasticNet_model,x_train_scaled)\n",
        "print('---'*25)"
      ],
      "metadata": {
        "id": "Mv9yk2v5h0Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_values = y_train.values.reshape((-1,))\n",
        "predicted_values = [y_pred_train.reshape((-1,)), y_pred_train_ridge.reshape((-1,)),\n",
        "                    y_pred_train_lasso.reshape((-1,)),y_pred_train_en.reshape((-1,))]\n",
        "model = ['Linear Regression', 'Ridge Regression', 'Lasso Regression','ElasticNet Regression']\n",
        "plt.figure(figsize=(15,4))\n",
        "i=1\n",
        "for preds in predicted_values:\n",
        "    plt.subplot(1,4,i)\n",
        "    sns.scatterplot(x=actual_values, y=preds,color='g')\n",
        "    plt.plot([np.min(actual_values), np.max(actual_values)], [np.min(actual_values), np.max(actual_values)], 'r-')\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title(model[i-1],fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "    i+=1\n",
        "plt.tight_layout()\n",
        "sns.despine()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "OT3JnEvkh4zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_major_weights = {\"Linear Model\":lr_model_weights,\n",
        "                       \"Ridge Model\":ridge_model_weights,\n",
        "                       \"Lasso Model\":lasso_model_weights,\n",
        "                       \"Elastic_Net\":en_model_weights}\n",
        "# excluding w0-intercept\n",
        "plt.figure(figsize=(25,5))\n",
        "i=1\n",
        "for model,data in model_major_weights.items():\n",
        "    model_weights_data = data.melt()\n",
        "\n",
        "    plt.subplot(1,4,i)\n",
        "    sns.barplot(data=model_weights_data[:-1].sort_values(by='value',ascending=False),\n",
        "                y='variable', x='value',width=0.2,palette=['darkgreen','g','green','limegreen','seagreen','mediumseagreen'])\n",
        "    plt.xlabel('Features')\n",
        "    plt.ylabel('Coefficient/Weight')\n",
        "    plt.title(f'{model} Coefficients / weights',fontsize=12,fontfamily='serif',fontweight='bold',backgroundcolor='g',color='w')\n",
        "    i+=1\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AoLHpE0UiEdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Adj. R2 Score\n",
        "def adj_r(r_sq,X,Y):\n",
        "  adj_r1 = (1 - ((1-r_sq)*(len(Y)-1)) / (len(Y)-X.shape[1]-1))\n",
        "  return adj_r1\n",
        "\n",
        "def r2_score(y,y_):\n",
        "    num = np.sum((y-y_)**2)\n",
        "    denom = np.sum((y- y.mean())**2)\n",
        "    score = (1- num/denom)\n",
        "    return score"
      ],
      "metadata": {
        "id": "h-vswwSgiFE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "degrees = 4\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for degree in range(1, degrees):\n",
        "    # Putting the classes like PolynomialFeatures(), StandardScaler(), LinearRegression() into a pipeline\n",
        "    polyreg_scaled = make_pipeline(PolynomialFeatures(degree), StandardScaler(), LinearRegression())\n",
        "    polyreg_scaled.fit(x_train_scaled, y_train)\n",
        "\n",
        "    # Calculate R2 Score for train and test data\n",
        "    train_score = polyreg_scaled.score(x_train_scaled, y_train) # R2 TRAIN\n",
        "    test_score = polyreg_scaled.score(x_test_scaled, y_test) # R2 TEST\n",
        "\n",
        "    # Calculate Adj. R2 Score for train and test data\n",
        "    train_scores.append(adj_r(train_score,x_train_scaled,y_train))\n",
        "    test_scores.append(adj_r(test_score,x_test_scaled,y_test))\n",
        "\n",
        "    # Calculate the y_pred for train and test data\n",
        "    output1 = polyreg_scaled.predict(x_train_scaled)\n",
        "    output2 = polyreg_scaled.predict(x_test_scaled)\n",
        "\n",
        "    # Calculate the MSE for train and test data\n",
        "    train_loss.append(mean_squared_error(y_train,output1)) # MSE train\n",
        "    test_loss.append(mean_squared_error(y_test,output2)) # MSE test"
      ],
      "metadata": {
        "id": "Mo2LuGx3iFH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TkdR11oAiFMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# Plot Adjusted R-scores\n",
        "axes[0].plot(list(range(1, degrees)), train_scores, label=\"train\")\n",
        "axes[0].plot(list(range(1, degrees)), test_scores, label=\"test\")\n",
        "axes[0].axvline(x=2, color='g', linestyle='--', label=\"degree=2\")\n",
        "axes[0].legend(loc='lower left')\n",
        "axes[0].set_xlabel(\"Degree\")\n",
        "axes[0].set_ylabel(\"Adj. R² Score\")\n",
        "axes[0].set_title(\"Adjusted R² Score vs. Degree\", fontsize=12, fontfamily='serif', fontweight='bold', backgroundcolor='g', color='w')\n",
        "\n",
        "# Plot Mean Squared Errors\n",
        "axes[1].plot(list(range(1, degrees)), train_loss, label=\"train\")\n",
        "axes[1].plot(list(range(1, degrees)), test_loss, label=\"test\")\n",
        "axes[1].axvline(x=2, color='g', linestyle='--', label=\"degree=2\")\n",
        "axes[1].legend(loc='upper left')\n",
        "axes[1].set_xlabel(\"Degree\")\n",
        "axes[1].set_ylabel(\"MSE\")\n",
        "axes[1].set_title(\"Mean Squared Error vs. Degree\", fontsize=12, fontfamily='serif', fontweight='bold', backgroundcolor='g', color='w')\n",
        "\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TJgHyu8WiFPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rate_list = list(range(1, degrees))"
      ],
      "metadata": {
        "id": "PQB1azW1iFSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best degree\n",
        "index = np.argmax(test_scores)\n",
        "best_degree = rate_list[index]\n",
        "best_degree"
      ],
      "metadata": {
        "id": "7oFmCKnoiFU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polynomial Regression\n",
        "\n",
        "# Transform the features into polynomial features\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "degree = 2\n",
        "poly = PolynomialFeatures(degree=degree)\n",
        "X_train_poly = poly.fit_transform(x_train_scaled)\n",
        "X_test_poly = poly.transform(x_test_scaled)"
      ],
      "metadata": {
        "id": "Ck25PlgEiMtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of X_train and X_test\n",
        "x_train_scaled.shape, x_test_scaled.shape"
      ],
      "metadata": {
        "id": "LyAK8-M-iMxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polynomial features been created\n",
        "X_train_poly.shape, X_test_poly.shape"
      ],
      "metadata": {
        "id": "omXmazVciM0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the polynomial features\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
        "X_test_poly_scaled = scaler.transform(X_test_poly)"
      ],
      "metadata": {
        "id": "uLk2XqPziM4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required library\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "Polynomial_Reg_model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "Polynomial_Reg_model.fit(X_train_poly_scaled, y_train)"
      ],
      "metadata": {
        "id": "tblUdhSUiM7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting values for the test data\n",
        "y_pred_train_poly = Polynomial_Reg_model.predict(X_train_poly_scaled)\n",
        "y_pred_test_poly = Polynomial_Reg_model.predict(X_test_poly_scaled)"
      ],
      "metadata": {
        "id": "prHHaqPpiT13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance of Polynomial Regression\n",
        "print(\"Performance of Polynomial Regression\")\n",
        "print(\"-\"*36)\n",
        "print(\"Performance of Train data\")\n",
        "print(\"-\"*26)\n",
        "model_evaluation(y_train, y_pred_train_poly, Polynomial_Reg_model,x_test_scaled)\n",
        "print()\n",
        "print(\"Performance of Test data\")\n",
        "print(\"-\"*26)\n",
        "model_evaluation(y_test, y_pred_test_poly, Polynomial_Reg_model,x_test_scaled)"
      ],
      "metadata": {
        "id": "pWfPZnXciUJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual vs Predicted\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Actual vs Predicted Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_train, y_pred_train_poly,color=\"green\")\n",
        "plt.plot([np.min(actual_values), np.max(actual_values)], [np.min(actual_values), np.max(actual_values)], 'r-')\n",
        "plt.xlabel('Actual_train (y_train)')\n",
        "plt.ylabel('Predicted_train (y_pred_train)')\n",
        "plt.title('Training data')\n",
        "\n",
        "# Actual vs Predicted Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_pred_test_poly, color=\"green\")\n",
        "plt.plot([np.min(actual_values), np.max(actual_values)], [np.min(actual_values), np.max(actual_values)], 'r-')\n",
        "plt.xlabel('Actual_test (y_test)')\n",
        "plt.ylabel('Predicted_test (y_pred_test)')\n",
        "plt.title('Testing data')\n",
        "\n",
        "plt.suptitle(\"Actual vs Predicted - Polynomial Regression\", fontsize = 15, fontfamily='serif', fontweight='bold', backgroundcolor='g', color='w')\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VvqKrs1kiUOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = x_train_scaled\n",
        "X_test = x_test_scaled"
      ],
      "metadata": {
        "id": "WWE79Hb3iURi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning: find the best regularization strength\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "\n",
        "# To find best lambda\n",
        "degree = 2 # is best\n",
        "\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "rate_list = np.linspace(0,0.003,50)\n",
        "\n",
        "for rate in rate_list:\n",
        "\n",
        "  # Creating pipeline()\n",
        "  polyreg_scaled = make_pipeline(PolynomialFeatures(2), StandardScaler(), Lasso(alpha=rate))\n",
        "  polyreg_scaled.fit(X_train, y_train)\n",
        "\n",
        "  # Calculate R2 Score for train and test data\n",
        "  train_score = polyreg_scaled.score(X_train, y_train)\n",
        "  test_score = polyreg_scaled.score(X_test, y_test)\n",
        "\n",
        "  # Calculate Adj. R2 Score for train and test data\n",
        "  train_scores.append(adj_r(train_score,X_train,y_train))\n",
        "  test_scores.append(adj_r(test_score,X_test,y_test))\n"
      ],
      "metadata": {
        "id": "_FXomrs5iUUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Lambda (or) alpha\n",
        "index = np.argmax(test_scores)\n",
        "best_lambda = rate_list[index]\n",
        "best_lambda"
      ],
      "metadata": {
        "id": "q00j-ChuiatO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# Plot train and test scores\n",
        "plt.plot(rate_list, train_scores, label=\"train\")\n",
        "plt.plot(rate_list, test_scores, label=\"val\")\n",
        "\n",
        "# Scatter plot for the best lambda\n",
        "plt.scatter(best_lambda + 0.000034, test_scores[index], color='g', s=100, label=f\"Best λ = {best_lambda:.4f}\")\n",
        "# plt.annotate(f\"Best λ = {best_lambda:.4f}\",\n",
        "#              xy=(best_lambda, test_scores[index]),\n",
        "#              xytext=(best_lambda + 0.0001, test_scores[index] - 0.02),\n",
        "#              arrowprops=dict(facecolor='red', arrowstyle='->'),\n",
        "#              fontsize=12, color='red')\n",
        "\n",
        "# Styling and labels\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel(\"lambda\")\n",
        "plt.ylabel(\"R² Score\")\n",
        "plt.title(\"Polynomial Regression - Hyperparameter Tuning\",\n",
        "          fontsize=15, fontfamily='serif', fontweight='bold', backgroundcolor='g', color='w')\n",
        "plt.grid()\n",
        "sns.despine()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YSq8Q_wXiawf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Lasso model\n",
        "# degree 2 and lambda :0.0019591836734693877\n",
        "final_lasso_model_pipe = make_pipeline(PolynomialFeatures(2), StandardScaler(), Lasso(alpha=best_lambda))\n",
        "final_lasso_model_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predicting values for the train and test data\n",
        "y_pred_train_lasso = final_lasso_model_pipe.predict(X_train)\n",
        "y_pred_test_lasso = final_lasso_model_pipe.predict(X_test)\n",
        "\n",
        "# Performance of Lasso Regression\n",
        "print(\"Performance of Lasso Regression\")\n",
        "print(\"-\"*36)\n",
        "# Metrix for train and test data\n",
        "print(\"Performance of Train data\")\n",
        "print(\"-\"*26)\n",
        "model_evaluation(y_train, y_pred_train_lasso, final_lasso_model_pipe,x_train_scaled)\n",
        "print()\n",
        "print(\"Performance of Test data\")\n",
        "print(\"-\"*26)\n",
        "model_evaluation(y_test, y_pred_test_lasso, final_lasso_model_pipe,x_train_scaled)"
      ],
      "metadata": {
        "id": "FEsFxdwUia2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual vs Predicted\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Actual vs Predicted Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_train, y_pred_train_lasso,color=\"g\")\n",
        "plt.plot([np.min(actual_values), np.max(actual_values)], [np.min(actual_values), np.max(actual_values)], 'r-')\n",
        "plt.xlabel('Actual_train (y_train)')\n",
        "plt.ylabel('Predicted_train (y_pred_train)')\n",
        "plt.title('Training data')\n",
        "\n",
        "# Actual vs Predicted Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_pred_test_lasso, color=\"green\")\n",
        "plt.plot([np.min(actual_values), np.max(actual_values)], [np.min(actual_values), np.max(actual_values)], 'r-')\n",
        "plt.xlabel('Actual_test (y_test)')\n",
        "plt.ylabel('Predicted_test (y_pred_test)')\n",
        "plt.title('Testing data')\n",
        "\n",
        "plt.suptitle(\"Actual vs Predicted - Lasso Polynomial Regression\", fontsize = 15, fontfamily='serif', fontweight='bold', backgroundcolor='g', color='w')\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xmturv7difGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning: find the best regularization strength\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "\n",
        "# To find best lambda\n",
        "degree = 2 # is best\n",
        "\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "rate_list = np.linspace(0,0.0002,10)\n",
        "\n",
        "for rate in rate_list:\n",
        "\n",
        "  # Creating pipeline()\n",
        "  polyreg_scaled = make_pipeline(PolynomialFeatures(2), StandardScaler(), Ridge(alpha=rate))\n",
        "  polyreg_scaled.fit(X_train, y_train)\n",
        "\n",
        "  # Calculate R2 Score for train and test data\n",
        "  train_score = polyreg_scaled.score(X_train, y_train)\n",
        "  test_score = polyreg_scaled.score(X_test, y_test)\n",
        "\n",
        "  # Calculate Adj. R2 Score for train and test data\n",
        "  train_scores.append(adj_r(train_score,X_train,y_train))\n",
        "  test_scores.append(adj_r(test_score,X_test,y_test))\n",
        "\n",
        "# Plote\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(rate_list, train_scores, label=\"train\")\n",
        "plt.plot(rate_list, test_scores, label=\"val\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel(\"lambda\")\n",
        "plt.ylabel(\"R-score\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DpnhqHqxifJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Lambda (or) alpha\n",
        "index = np.argmax(test_scores)\n",
        "best_lambda_Ridge = rate_list[index]\n",
        "best_lambda_Ridge"
      ],
      "metadata": {
        "id": "rdFniMo6ifQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# Plot train and test scores\n",
        "plt.plot(rate_list, train_scores, label=\"train\")\n",
        "plt.plot(rate_list, test_scores, label=\"val\")\n",
        "\n",
        "# Scatter plot for the best lambda\n",
        "plt.scatter(best_lambda_Ridge, test_scores[index], color='g', s=100, label=f\"Best λ = {best_lambda_Ridge:.6f}\")\n",
        "# plt.annotate(f\"Best λ = {best_lambda:.4f}\",\n",
        "#              xy=(best_lambda, test_scores[index]),\n",
        "#              xytext=(best_lambda + 0.0001, test_scores[index] - 0.02),\n",
        "#              arrowprops=dict(facecolor='red', arrowstyle='->'),\n",
        "#              fontsize=12, color='red')\n",
        "\n",
        "# Styling and labels\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel(\"lambda\")\n",
        "plt.ylabel(\"R² Score\")\n",
        "plt.title(\"Polynomial Regression - Hyperparameter Tuning\",\n",
        "          fontsize=15, fontfamily='serif', fontweight='bold', backgroundcolor='g', color='w')\n",
        "plt.grid()\n",
        "sns.despine()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "O4F5pdfjijRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Lasso model\n",
        "# degree: 2 and lambda :2.2222222222222223e-05\n",
        "final_ridge_model_pipe = make_pipeline(PolynomialFeatures(2), StandardScaler(), Ridge(alpha=best_lambda_Ridge))\n",
        "final_ridge_model_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predicting values for the train and test data\n",
        "y_pred_train_ridge = final_ridge_model_pipe.predict(X_train)\n",
        "y_pred_test_ridge = final_ridge_model_pipe.predict(X_test)\n",
        "\n",
        "# Performance of Ridge Regression\n",
        "print(\"Performance of Ridge Regression\")\n",
        "print(\"-\"*36)\n",
        "# Metrix for train and test data\n",
        "print(\"Performance of Train data\")\n",
        "print(\"-\"*26)\n",
        "model_evaluation(y_train, y_pred_train_ridge, final_ridge_model_pipe,x_train_scaled)\n",
        "print()\n",
        "print(\"Performance of Test data\")\n",
        "print(\"-\"*26)\n",
        "model_evaluation(y_test, y_pred_test_ridge, final_ridge_model_pipe,x_train_scaled)"
      ],
      "metadata": {
        "id": "K9MDiRerijUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual vs Predicted\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# Actual vs Predicted Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_train, y_pred_train_ridge,color=\"g\")\n",
        "plt.plot([np.min(actual_values), np.max(actual_values)], [np.min(actual_values), np.max(actual_values)], 'r-')\n",
        "plt.xlabel('Actual_train (y_train)')\n",
        "plt.ylabel('Predicted_train (y_pred_train)')\n",
        "plt.title('Training data')\n",
        "\n",
        "# Actual vs Predicted Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_pred_test_ridge, color=\"green\")\n",
        "plt.plot([np.min(actual_values), np.max(actual_values)], [np.min(actual_values), np.max(actual_values)], 'r-')\n",
        "plt.xlabel('Actual_test (y_test)')\n",
        "plt.ylabel('Predicted_test (y_pred_test)')\n",
        "plt.title('Testing data')\n",
        "\n",
        "plt.suptitle(\"Actual vs Predicted - RIDGE Polynomial Regression\", fontsize = 15, fontfamily='serif', fontweight='bold', backgroundcolor='g', color='w')\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fj37kdbiijcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning: find the best regularization strength\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# To find best lambda\n",
        "degree = 2 # is best\n",
        "\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "rate_list = np.linspace(0,0.006,10)\n",
        "\n",
        "for rate in rate_list:\n",
        "\n",
        "  # Creating pipeline()\n",
        "  polyreg_scaled = make_pipeline(PolynomialFeatures(2), StandardScaler(), ElasticNet(alpha=rate))\n",
        "  polyreg_scaled.fit(X_train, y_train)\n",
        "\n",
        "  # Calculate R2 Score for train and test data\n",
        "  train_score = polyreg_scaled.score(X_train, y_train)\n",
        "  test_score = polyreg_scaled.score(X_test, y_test)\n",
        "\n",
        "  # Calculate Adj. R2 Score for train and test data\n",
        "  train_scores.append(adj_r(train_score,X_train,y_train))\n",
        "  test_scores.append(adj_r(test_score,X_test,y_test))\n",
        "\n",
        "  # Best Lambda (or) alpha\n",
        "index = np.argmax(test_scores)\n",
        "best_lambda_ElasticNet = rate_list[index]\n",
        "print(f\"best_lambda_ElasticNet : {best_lambda_ElasticNet}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "# Plot train and test scores\n",
        "plt.plot(rate_list, train_scores, label=\"train\")\n",
        "plt.plot(rate_list, test_scores, label=\"val\")\n",
        "\n",
        "# Scatter plot for the best lambda\n",
        "plt.scatter(best_lambda_ElasticNet, test_scores[index], color='g', s=100, label=f\"Best λ = {best_lambda_Ridge:.6f}\")\n",
        "# plt.annotate(f\"Best λ = {best_lambda:.4f}\",\n",
        "#              xy=(best_lambda, test_scores[index]),\n",
        "#              xytext=(best_lambda + 0.0001, test_scores[index] - 0.02),\n",
        "#              arrowprops=dict(facecolor='red', arrowstyle='->'),\n",
        "#              fontsize=12, color='red')\n",
        "\n",
        "# Styling and labels\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel(\"lambda\")\n",
        "plt.ylabel(\"R² Score\")\n",
        "plt.suptitle(\"Actual vs Predicted - ELASTICNET Polynomial Regression\", fontsize = 15, fontfamily='serif', fontweight='bold', backgroundcolor='g', color='w')\n",
        "plt.grid()\n",
        "sns.despine()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kcx1WNblioW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final ElasticNet model\n",
        "# degree: 2 and lambda :0.004\n",
        "final_ElasticNet_model_pipe = make_pipeline(PolynomialFeatures(2), StandardScaler(), Ridge(alpha=best_lambda_ElasticNet))\n",
        "final_ElasticNet_model_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predicting values for the train and test data\n",
        "y_pred_train_ElasticNet = final_ElasticNet_model_pipe.predict(X_train)\n",
        "y_pred_test_ElasticNet = final_ElasticNet_model_pipe.predict(X_test)\n",
        "\n",
        "# Performance of ElasticNet Regression\n",
        "print(\"Performance of ElasticNet Regression\")\n",
        "print(\"-\"*36)\n",
        "# Metrix for train and test data\n",
        "print(\"Performance of Train data\")\n",
        "print(\"-\"*26)\n",
        "model_evaluation(y_train, y_pred_train_ElasticNet, final_ElasticNet_model_pipe,x_test_scaled)\n",
        "print()\n",
        "print(\"Performance of Test data\")\n",
        "print(\"-\"*26)\n",
        "model_evaluation(y_test, y_pred_test_ElasticNet, final_ElasticNet_model_pipe,x_test_scaled)"
      ],
      "metadata": {
        "id": "MekH8bDuiqDW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}